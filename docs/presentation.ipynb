{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Nonnegative Matrix Factorisation for Audio Applications\n",
    "## Dan Jacobellis, Tyler Masthay\n",
    "![](VWH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nonnegative Matrix Factorisation\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "$$ \\bf V \\approx \\hat {\\bf V} = \\bf W \\bf H$$\n",
    "\n",
    "$$\\matrix{\n",
    "\\bf W \\in \\Bbb R^{m \\times k} & \\bf W \\geq 0 \\\\\n",
    "\\bf H \\in \\Bbb R^{k \\times n} & \\bf H \\geq 0}$$\n",
    "\n",
    "\n",
    "- Unsupervised learning (think SVD)\n",
    "- Number of components $k$ is a parameter\n",
    "- $\\bf V$ is $m \\times n$\n",
    "- Setting $k \\lt m$ is a form of lossy compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Audio Example\n",
    "\n",
    "## $\\bf V =\\left| CQT(x) \\right|=$\n",
    "\n",
    "![](V.png)\n",
    "\n",
    "*Time-frequency representation of 'Korobeiniki' played on piano. The frequency is on a logarithmic scale.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Example\n",
    "\n",
    "## $\\bf V =\\left| CQT(x) \\right|=$\n",
    "\n",
    "![](V_poly.png)\n",
    "\n",
    "*Time-frequency representation of 'Korobeiniki' (polyphonic).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The phase information is less important to our perception of the audio than the magnitude, so we take the magnitude of the time-frequency decomposition. This is why we need nonnegative. There is no such thing as a negative note or a negative speech.\n",
    "\n",
    "Notice that even though the recording consists of a single instrument (piano) playing a monophonic melody, the harmonics of each note create replicas of the actual melody at integer multiples of the fundamental frequency. The complexity that arises from mixing multiple intruments or adding any amount of polyphony makes direct analysis of the time-frequency image intractable for most tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Audio Example\n",
    "\n",
    "![](VWH.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "When $k \\lt m$ , and we search for a factorization that approximately matches $\\bf V$, we perform unsupervised learning. $\\bf W$ contains a learned dictionary and $\\bf H$ contains a representation of $\\bf V$ in terms of this dictionary. \n",
    "\n",
    "This makes many forms of audio analysis more tractable, especially source separation and music transcription."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithm: Multiplicative Update\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "* Initialize $\\bf W$ and $\\bf H$ with non-negative values\n",
    "* Iteratively update $\\bf W$ and $\\bf H$ using the following rules: ($n$ here is the iteration)\n",
    "\n",
    "$$\n",
    "{\\bf H}_{[i,j]}^{n+1}\\leftarrow {\\bf H}_{[i,j]}^{n} \\odot \\frac\n",
    "{\\left( ({\\bf W}^{n})^\\top \\bf V \\right)_{[i,j]}}\n",
    "{\\left( ({\\bf W}^n)^\\top {\\bf W}^n {\\bf H}^n \\right)_{[i,j]}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "{\\bf W}_{[i,j]}^{n+1}\\leftarrow {\\bf W}_{[i,j]}^{n} \\odot \\frac\n",
    "{\\left( {\\bf V} ({\\bf H}^{n+1})^\\top \\right)_{[i,j]}}\n",
    "{\\left( {\\bf W}^n {\\bf H}^{n+1} ({\\bf H}^{n+1})^\\top \\right)_{[i,j]}}\n",
    "$$\n",
    "\n",
    "$\\odot$ and division are element-wise.\n",
    "\n",
    "ref. Lee, D.D., Seung, H.S., 2001. Algorithms for Non-negative Matrix Factorization, in: Advances in Neural Information Processing Systems 13. MIT Press, pp. 556â€“562."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithm: Multiplicative Update\n",
    "\n",
    "![](DAG1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Must be careful with order of operations, otherwise the matrix size will be increased unnecessarily.\n",
    "\n",
    "We want to exploit all of these embarassingly parallel steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parallelization on GPU : Motivation\n",
    "\n",
    "- Matricies remain stationary in memory\n",
    "- Matrix multiplies have high computational intensity compared to memory\n",
    "- Single precision is sufficient\n",
    "- Would like to use consumer hardware\n",
    "\n",
    "![](mobileGPU.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Since we have good memory locality and high computational intensity (high flops to mops) the algorithm is a good fit for GPU.\n",
    "\n",
    "One of the typical drawbacks to using GPU is poor double precision, but most audio is 16 bit fixed point, so single is sufficient.\n",
    "\n",
    "Applications become much more useful if we can use consumer or even mobile hardware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU Implementation\n",
    "\n",
    "- Used Julia bindings to CUDA (CURAND, CUBLAS)\n",
    "- Compiler allows easily mapping high level syntax to GPU\n",
    "- Compiler finds best way to send data back and forth between device and host\n",
    "![](PTX.png)\n",
    "\n",
    "ref. https://github.com/JuliaGPU/CUDAnative.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GPU Implementation\n",
    "- Must be careful and explicit with types and constants\n",
    "- Otherwise, compiler will think you want to move all of the data off of the GPU and back\n",
    "![](nvprof.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GPU Performance\n",
    " ![](gpu_runtime.png)\n",
    " \n",
    " - Runtime is relatively flat as the number of components increases up to a point\n",
    " - We can't fit everying in GPU memory after the number of components reaches ~128\n",
    " - After this point, we are forced to send data between CPU and GPU *every* iteration\n",
    " - Fortunately, the behavior as a function of the audio length is well-behaved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Compilation Performance\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![](Compilation.png)\n",
    " \n",
    " - Left figure shows orders of magnitude slowdown on the initial compilation of code for a variety of commonly used functions\n",
    " - Right figure shows speedup for subsequent compilations of code\n",
    " \n",
    " ref. Besard et. al. *Effective Extensible Programming: Unleashing Julia on GPUs*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lines of Code\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "![](Rodinia.png)\n",
    " \n",
    " - Lines of host and device code for Rodinia benchmarks. Comparison between CUDA C and Julia implementations.\n",
    " - On average, device code reduced by 8 percent and host code by 38 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GPU Performance\n",
    " ![](gpu_runtime.png)\n",
    " \n",
    " - Runtime is relatively flat as the number of components increases up to a point\n",
    " - We can't fit everying in GPU memory after the number of components reaches ~128\n",
    " - After this point, we are forced to send data between CPU and GPU *every* iteration\n",
    " - Fortunately, the behavior as a function of the audio length is well-behaved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CPU Performance\n",
    "\n",
    "![](cpu_runtime.png)\n",
    "\n",
    "- Scikit-learn implementation would require many CPU cores to match GPU runtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](cpu_gpu_table.png)\n",
    "\n",
    "Runtime (in seconds) vs number of components $(k)$ vs length of processed audio ($n$) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "\n",
    "## $\\bf V =\\left| CQT(x) \\right|=$\n",
    "\n",
    "![](V.png)\n",
    "\n",
    "*Time-frequency representation of 'Korobeiniki' (monophonic).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "![](W.png)\n",
    "\n",
    "*$\\bf W$ matrix arranged by fundamental frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "![](H.png)\n",
    "\n",
    "*$\\bf H$ matrix collapsed into midi note bins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "\n",
    "## $\\bf V =\\left| CQT(x) \\right|=$\n",
    "\n",
    "![](V_poly.png)\n",
    "\n",
    "*Time-frequency representation of 'Korobeiniki' (polyphonic).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "![](W_poly.png)\n",
    "\n",
    "*$\\bf W$ matrix arranged by fundamental frequency*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Demonstration\n",
    "![](H_poly.png)\n",
    "\n",
    "*$\\bf H$ matrix collapsed into midi note bins*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backup\n",
    "![](TFP.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
